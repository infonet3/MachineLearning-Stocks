/*
 * To change this template, choose Tools | Templates
 * and open the template in the editor.
 */
package Linear_Regression;

import java.util.List;
import static Linear_Regression.Matrix.getAverages;
import static Linear_Regression.Matrix.getRanges;

/**
 *
 * @author Matt Jones
 */
public class LinearRegression {

    /**
     * @param args the command line arguments
     */
    public static void runLinearRegression() {
        Dataset ds = new Dataset();

        ds.loadData();

        double[][] trainingMatrix = ds.getTrainingSet();
        double[] results = ds.getResultingValues();
        
        //Apply Mean Normalization to minimize work of gradient descent
        double[] averages = Matrix.getAverages(trainingMatrix);
        double[] ranges = Matrix.getRanges(trainingMatrix);
        
        trainingMatrix = Matrix.meanNormalization(trainingMatrix, averages, ranges);
        
        //Initialize Theta
        double[] theta = new double[trainingMatrix[0].length];
        for (int i = 0; i < theta.length; i++) {
            theta[i] = 1.0;
        }
        
        //Run Gradient Descent 10 times
        double costFunction;
        for (int i = 0; i < 100; i++) {
            LinearRegFormulas.gradientDescent(trainingMatrix, theta, results);
            costFunction = LinearRegFormulas.costFunction(trainingMatrix, theta, results);
            
            System.out.println("Cost Function = " + costFunction);
        }

        //Now test the values of thetas
        for (int i = 0; i < trainingMatrix.length; i++) {
            double mpg = theta[0] + theta[1] * trainingMatrix[i][1] + theta[2] * trainingMatrix[i][2] + theta[3] * trainingMatrix[i][3] + 
                    theta[4] * trainingMatrix[i][4] + theta[5] * trainingMatrix[i][5] + theta[6] * trainingMatrix[i][6];

            System.out.printf("Est: %.2f, Actual: %.2f %n", mpg, results[i]);
        }
    }
}
        
